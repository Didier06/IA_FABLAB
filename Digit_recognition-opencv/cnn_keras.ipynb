{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification version de keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/Didier06/IA_FABLAB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Un premier réseau de convolution avec Keras\n",
    "\n",
    "On utilise les couches `Conv2D` et `MaxPooling2D`. \n",
    "\n",
    "Remarque imortante : le tenseur d'entrée du réseau de convolution avec keras doit avoir les dimensions suivantes : `(hauteur image, largeur  image, canal de l'image)` \n",
    "Dans notre cas : `(28, 28, 1)`, format des images MNIST.  \n",
    "Pour réaliser cette opération exécuter cette commande :  \n",
    "`input_shape=(28, 28, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons la structure du réseau : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55744 (217.75 KB)\n",
      "Trainable params: 55744 (217.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Les sorties des couches `Conv2D` et `MaxPooling2D` sont des tenseurs 3D avec les dimensions `(hauteur, largeur, canaux)`.\n",
    "Le nombre de canaux est fixé par le 1er argument des couches  `Conv2D` (32 ou 64).\n",
    "\n",
    "Dans l'étape suivante on aplati (Flatten) la couche 3D en une couche 1D puis on retrouve 2 couches \"dense\".\n",
    "Avec pour la dernière une activaztion 'softmax'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons réalisé une classification avec 10 sorties.  \n",
    "Voici le modèle complet avec 93332 paramètres : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93322 (364.54 KB)\n",
      "Trainable params: 93322 (364.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tenseur `(3, 3, 64)` est transformé en tenseur 1D de dimension `(576,)`, avant la classification avec les 2 couches 'Dense'  \n",
    "\n",
    "Entrainons le réseau de convolution : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1749 - accuracy: 0.9449\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0481 - accuracy: 0.9846\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0331 - accuracy: 0.9898\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0252 - accuracy: 0.9920\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0198 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17990552c50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluons le modèle sur les données de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/modelcnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9905999898910522"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est très satisfaisant .... est meilleur que celui obtenu avec le réseau dense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prédictions avec une image dessinée sur paint.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x179945e6a10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reading png image file \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as img \n",
    "im = img.imread('images/digit_3.png')\n",
    "plt.imshow(im, cmap=plt.cm.binary)\n",
    "#print(im.shape)\n",
    "#print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Préparation de l'image dessinée et prédiction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Chiffre prédit :  3\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "def preprocess_image(image_path):# préparation de l'image\n",
    "    img = Image.open(image_path).convert('L')  # Convertir en niveau de gris grayscale\n",
    "    img = ImageOps.invert(img)                 # inverse l'image pour qu'elle soit conforme aux images MNIST\n",
    "    img = img.resize((28, 28))                 # Redimensionnement à 28x28\n",
    "    img = np.array(img)                        # Convertir en tableau numpy\n",
    "    img = img / 255.0                          # on normalise les valeurs des pixels\n",
    "    img = img.reshape(1,28,28)                 # redimensionne en  (28,28) ( entrée du réseau cnn\n",
    "    return img\n",
    "\n",
    "processed_image = preprocess_image('images/digit_3.png') \n",
    "    \n",
    "predictions= model.predict(processed_image)# prévision \n",
    "\n",
    "print(predictions.round(2)) # résultat\n",
    "print(\"Chiffre prédit : \", predictions.argmax())# index  of the class with highest probability\n",
    "          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
